{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b7bc8-fcfc-4a7a-8c68-53c75cbe6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import INV\n",
    "import csv\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1525d3-8271-4393-ad10-3909482a4ca3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebc8cb-5384-437b-b0e2-247f580b057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model_and_tokenizer(name=\"qwen\"):\n",
    "    \n",
    "    path_dict = {\n",
    "        \"qwen\" : \"Qwen/Qwen1.5-7B-Chat\",\n",
    "        \"aya\" : \"CohereForAI/aya-101\",\n",
    "    }\n",
    "    \n",
    "    assert name in path_dict, \"unknown model\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-7B-Chat\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen1.5-7B-Chat\", torch_dtype=\"auto\")\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model, tokenizer = load_model_and_tokenizer(name=\"qwen\")\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9188a78-d209-4444-8a8d-a459e6d62e1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e2bd77-1675-4fba-aa36-1004dac031d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf9c6ec-817b-43d2-a47e-66366e7378d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse airline tweets\n",
    "\n",
    "def read_tweets(path):\n",
    "    r = csv.DictReader(open(path))\n",
    "    labels = []\n",
    "    confs = []\n",
    "    airlines = []\n",
    "    tdata = []\n",
    "    reasons = []\n",
    "    for row in r:\n",
    "        sentiment, conf, airline, text = row['airline_sentiment'], row['airline_sentiment_confidence'], row['airline'], row['text']\n",
    "        labels.append(sentiment)\n",
    "        confs.append(conf)\n",
    "        airlines.append(airline)\n",
    "        tdata.append(text)\n",
    "        reasons.append(row['negativereason'])\n",
    "\n",
    "    mapping = {'negative': 0, 'positive': 2, 'neutral': 1}\n",
    "    labels = np.array([mapping[x] for x in labels]).astype(int)\n",
    "    \n",
    "    return tdata, labels # labels, confs, airlines, tdata, reasons\n",
    "\n",
    "data, labels = read_tweets('./Tweets.csv')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "sentences = data\n",
    "parsed_data = list(nlp.pipe(sentences))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bf1591-be52-4d98-9ed6-b5c86e62a1b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Named Entity Recognition (NER) test using INVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc43d36-36df-4e43-b6bd-df248f5cb599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change location\n",
    "perturb_location_data = Perturb.perturb(parsed_data, Perturb.change_location, nsamples=1000, n=5).data\n",
    "\n",
    "# Change names\n",
    "perturb_names_data = Perturb.perturb(parsed_data, Perturb.change_names, nsamples=1000, n=5).data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cbf06b-1a16-4dc8-938e-0bd5e82a7c26",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Robustness using INVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd46a744-7826-4a61-929a-0e756f4fdaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import string\n",
    "\n",
    "def random_string(n):\n",
    "    return ''.join(np.random.choice([x for x in string.ascii_letters + string.digits], n))\n",
    "\n",
    "def random_url(n=6):\n",
    "    return 'https://t.co/%s' % random_string(n)\n",
    "\n",
    "def random_handle(n=6):\n",
    "    return '@%s' % random_string(n)\n",
    "\n",
    "def add_irrelevant(sentence):\n",
    "    urls_and_handles = [random_url(n=6) for _ in range(5)] + [random_handle() for _ in range(5)]\n",
    "    irrelevant_before = ['@airline '] + urls_and_handles\n",
    "    irrelevant_after = urls_and_handles \n",
    "    rets = ['%s %s' % (x, sentence) for x in irrelevant_before ]\n",
    "    rets += ['%s %s' % (sentence, x) for x in irrelevant_after]\n",
    "    return rets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08bc126-0749-4a0c-a433-d7dd0392df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add randomly generated URLs and handles\n",
    "perturb_irrelevant_data = Perturb.perturb(sentences, add_irrelevant, nsamples=1000).data\n",
    "\n",
    "# Add typos\n",
    "perturb_punc_data = Perturb.perturb(parsed_data, Perturb.punctuation, nsamples=1000).data\n",
    "perturb_typo1_data = Perturb.perturb(sentences, Perturb.add_typos, nsamples=1000, typos=1).data\n",
    "perturb_typo2_data = Perturb.perturb(sentences, Perturb.add_typos, nsamples=1000, typos=2).data\n",
    "perturb_typo5_data = Perturb.perturb(sentences, Perturb.add_typos, nsamples=1000, typos=5).data\n",
    "\n",
    "# Contract or expand contractions\n",
    "perturb_contract_data = Perturb.perturb(sentences, Perturb.contractions, nsamples=1000).data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf38bd-f210-412e-b994-6e87534e20bc",
   "metadata": {},
   "source": [
    "#### Vocab+POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81519c11-5b4a-4271-9827-680059d71da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "editor = checklist.editor.Editor()\n",
    "editor.tg\n",
    "\n",
    "air_noun = ['flight', 'seat', 'pilot', 'staff', 'service', 'customer service', 'aircraft', 'plane', 'food', 'cabin crew', 'company', 'airline', 'crew']\n",
    "editor.add_lexicon('air_noun', air_noun)\n",
    "\n",
    "pos_adj = ['good', 'great', 'excellent', 'amazing', 'extraordinary', 'beautiful', 'fantastic',\n",
    "           'nice', 'incredible', 'exceptional', 'awesome', 'perfect', 'fun', 'happy', 'adorable',\n",
    "           'brilliant', 'exciting', 'sweet', 'wonderful']\n",
    "neg_adj = ['awful', 'bad', 'horrible', 'weird', 'rough', 'lousy', 'unhappy', 'average',\n",
    "           'difficult', 'poor', 'sad', 'frustrating', 'hard', 'lame', 'nasty', 'annoying',\n",
    "           'boring', 'creepy', 'dreadful', 'ridiculous', 'terrible', 'ugly', 'unpleasant']\n",
    "neutral_adj = ['American', 'international',  'commercial', 'British', 'private', 'Italian',\n",
    "               'Indian', 'Australian', 'Israeli']\n",
    "\n",
    "editor.add_lexicon('pos_adj', pos_adj, overwrite=True)\n",
    "editor.add_lexicon('neg_adj', neg_adj, overwrite=True)\n",
    "editor.add_lexicon('neutral_adj', neutral_adj, overwrite=True)\n",
    "\n",
    "pos_verb_present = ['like', 'enjoy', 'appreciate', 'love',  'recommend', 'admire', 'value',\n",
    "                    'welcome']\n",
    "neg_verb_present = ['hate', 'dislike', 'regret',  'abhor', 'dread', 'despise' ]\n",
    "neutral_verb_present = ['see', 'find']\n",
    "pos_verb_past = ['liked', 'enjoyed', 'appreciated', 'loved', 'admired', 'valued', 'welcomed']\n",
    "neg_verb_past = ['hated', 'disliked', 'regretted',  'abhorred', 'dreaded', 'despised']\n",
    "neutral_verb_past = ['saw', 'found']\n",
    "\n",
    "editor.add_lexicon('pos_verb_present', pos_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neg_verb_present', neg_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb_present', neutral_verb_present, overwrite=True)\n",
    "editor.add_lexicon('pos_verb_past', pos_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neg_verb_past', neg_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb_past', neutral_verb_past, overwrite=True)\n",
    "editor.add_lexicon('pos_verb', pos_verb_present+ pos_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neg_verb', neg_verb_present + neg_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb', neutral_verb_present + neutral_verb_past, overwrite=True)\n",
    "\n",
    "neutral_words = set(['.', 'the', 'The', ',', 'a', 'A', 'and', 'of', 'to', 'it', 'that', 'in',\n",
    "                     'this', 'for',  'you', 'there', 'or', 'an', 'by', 'about', 'flight', 'my',\n",
    "                     'in', 'of', 'have', 'with', 'was', 'at', 'it', 'get', 'from', 'this',\n",
    "                     'Flight', 'plane'])\n",
    "\n",
    "forbidden = set(['No', 'no', 'Not', 'not', 'Nothing', 'nothing', 'without', 'but'] + \\\n",
    "                pos_adj + neg_adj + pos_verb_present + pos_verb_past + neg_verb_present + \\\n",
    "                neg_verb_past)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15055a54-6faf-44f8-a321-4bae34f480e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def change_neutral(d):\n",
    "    examples = []\n",
    "    subs = []\n",
    "    words_in = [x for x in d.capitalize().split() if x in neutral_words]\n",
    "    if not words_in:\n",
    "        return None\n",
    "    for w in words_in:\n",
    "        suggestions = [x for x in editor.suggest_replace(d, w, beam_size=5, words_and_sentences=True) if x[0] not in forbidden]\n",
    "        examples.extend([x[1] for x in suggestions])\n",
    "        subs.extend(['%s -> %s' % (w, x[0]) for x in suggestions])\n",
    "    if examples:\n",
    "        idxs = np.random.choice(len(examples), min(len(examples), 10), replace=False)\n",
    "        return [examples[i] for i in idxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d093af-f6cd-4bab-94ea-6ebc56692e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace neutral words with other neutral words (INV)\n",
    "perturb_change_neutral_data = Perturb.perturb(sentences, change_neutral, nsamples=1000).data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3440fc7e-938f-4944-98c8-ba98bf437b89",
   "metadata": {},
   "source": [
    "#### Vocab+POS using DIRectional expectation test (DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c3bef-eb96-4869-9af0-feb69dce3220",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba52ba7-cf99-42e9-a00b-1480b19825c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ad683-89fb-4764-b40d-48840cf040d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8103d5-b73a-4d7f-b335-eebeb34a3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def response_from_generate(model, messages):\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "    generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=1)\n",
    "    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    output_mapping = {'A' : 0, 'B' : 1, 'C' : 2}\n",
    "    \n",
    "    return output_mapping[response]\n",
    "\n",
    "\n",
    "def response_from_forward(model, messages):\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "    output = model.forward(model_inputs.input_ids)\n",
    "    \n",
    "    # idx 32 = A (positive), idx 33 = B (negative), idx 34 = C (neutral)\n",
    "    response = torch.argmax(output.logits[0, -1, 32:35]).item()\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def inference(model, data, inference_mode='generate'):\n",
    "    \"\"\"\n",
    "    Perform inference on model using created data samples. The first sentence\n",
    "    in each list of strings is the gold label. inference_mode='generate' means\n",
    "    .generate() is used to create a written response; inference_mode='forward'\n",
    "    means .forward() uses the output logits to determine the response.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_message = \"Give the sentiment of the user's prompt. Please only respond with A (positive), B (negative) or C (neutral).\"\n",
    "    \n",
    "    gold_labels, pred_labels = [], []\n",
    "    \n",
    "    for sentences in tqdm(data):\n",
    "        sentence_labels = []\n",
    "        for i, user_prompt in enumerate(sentences):\n",
    "\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "            \n",
    "            if inference_mode == 'generate':\n",
    "                response = response_from_generate(model, messages)\n",
    "            elif inference_mode == 'forward':\n",
    "                response = response_from_forward(model, messages)\n",
    "            else:\n",
    "                assert False, 'unknown inference mode'\n",
    "            \n",
    "            if i == 0:\n",
    "                gold_labels.append(response)\n",
    "            else:\n",
    "                sentence_labels.append(response)\n",
    "        \n",
    "        pred_labels.append(sentence_labels)\n",
    "    \n",
    "    return gold_labels, pred_labels\n",
    "\n",
    "\n",
    "# gold_labels, pred_labels = inference(model, perturb_location_data, inference_mode='forward')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521bafe3-461d-448c-bf65-c694829dcc07",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a43059-eb74-413a-9a5d-5e2462ab2750",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(gold_labels, pred_labels):\n",
    "    \n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    for i, sentence_labels in enumerate(pred_labels):\n",
    "        for prompt_label in sentence_labels:\n",
    "            y_pred.append(prompt_label)\n",
    "            y_true.append(gold_labels[i])\n",
    "    \n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "# evaluate(gold_labels, pred_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c836d30e-3350-4d6c-81e3-e0edc27d91a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637ad1f-b9b4-427d-acb0-04b837c7d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment NER INV\n",
    "\n",
    "gold_labels, pred_labels = inference(model, perturb_location_data, inference_mode='forward')\n",
    "print(f'Accuracy: {evaluate(gold_labels, pred_labels):.2f}')\n",
    "\n",
    "gold_labels, pred_labels = inference(model, perturb_names_data, inference_mode='forward')\n",
    "print(f'Accuracy: {evaluate(gold_labels, pred_labels):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d5386-85f4-4a42-8dff-3775a5f17447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Robust. INV\n",
    "\n",
    "gold_labels, pred_labels = inference(model, perturb_irrelevant_data, inference_mode='forward')\n",
    "print(f'Accuracy: {evaluate(gold_labels, pred_labels):.2f}')\n",
    "\n",
    "gold_labels, pred_labels = inference(model, perturb_punc_data, inference_mode='forward')\n",
    "print(f'Accuracy: {evaluate(gold_labels, pred_labels):.2f}')\n",
    "\n",
    "gold_labels, pred_labels = inference(model, perturb_typo1_data, inference_mode='forward')\n",
    "print(f'Accuracy: {evaluate(gold_labels, pred_labels):.2f}')\n",
    "\n",
    "gold_labels, pred_labels = inference(model, perturb_typo2_data, inference_mode='forward')\n",
    "print(f'Accuracy: {evaluate(gold_labels, pred_labels):.2f}')\n",
    "\n",
    "gold_labels, pred_labels = inference(model, perturb_typo5_data, inference_mode='forward')\n",
    "print(f'Accuracy: {evaluate(gold_labels, pred_labels):.2f}')\n",
    "\n",
    "gold_labels, pred_labels = inference(model, perturb_contract_data, inference_mode='forward')\n",
    "print(f'Accuracy: {evaluate(gold_labels, pred_labels):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494520e3-db32-4533-bc80-9c8b9d44eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gold_labels, pred_labels = inference(model, perturb_change_neutral_data, inference_mode='forward')\n",
    "print(f'Accuracy: {evaluate(gold_labels, pred_labels):.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atcs",
   "language": "python",
   "name": "atcs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
